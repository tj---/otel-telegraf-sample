########################################################################################################################
# Receivers
########################################################################################################################
receivers:
 # https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/receiver/simpleprometheusreceiver
 # This is being used to scrape the OTel Collector metrics from itself
 prometheus_simple:
   collection_interval: 10s
   endpoint: "0.0.0.0:8888"
 # Influx receiver (http) - Currently in Beta
 influxdb:
   # https://pkg.go.dev/github.com/open-telemetry/opentelemetry-collector-contrib/receiver/influxdbreceiver#section-readme
   # Apparently, only HTTP service endpoint for the line protocol receiver 
   endpoint: 0.0.0.0:19000

 # Carbon / Graphite receiver - Currently in Beta
 # All the details are present here:
 # https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/receiver/carbonreceiver
 carbon:
   endpoint: 0.0.0.0:2003
   transport: tcp
   tcp_idle_timeout: 10s
   parser:
     type: regex
     config:
       # Matches the first rule
       rules:
         # When the metrics are forwarded from Telegraf to OTel, the hostname is being added
         # <key_X> makes labels while <name_Y> makes metric names
         # Sender_Host.Cluster.c891.node74.Diamond-Telegraf.temperature.max
         - regexp: "^(?P<key_sender_host>[^.]+)\\.(?P<key_type>[^.]+)\\.(?P<key_custer_id>[^.]+)\\.(?P<key_node>[^.]+)\\.(?P<name_tkn3>[^.]+)\\.(?P<key_tkn4>[^.]+)\\.(?P<name_tkn5>[^.]+)$"
           name_prefix: ""
           type: gauge
         # Sender_Host.Cluster.c891.node74.Diamond-Telegraf.foo.bar.weather.xyz
         - regexp: "^(?P<key_sender_host>[^.]+)\\.(?P<key_type>[^.]+)\\.(?P<key_custer_id>[^.]+)\\.(?P<key_node>[^.]+)\\.(?P<key_tkn3>[^.]+)\\.(?P<key_tkn4>[^.]+)\\.(?P<key_tkn5>[^.]+)\\.(?P<name_measurement1>[^.]+)\\.(?P<name_measurement2>[^.]+)$"
           name_prefix: ""
           type: cumulative
       name_separator: "_"

 # OTLP receivers
 otlp:
   protocols:
     http:
       endpoint: 0.0.0.0:4318
     grpc:
       endpoint: 0.0.0.0:4317

########################################################################################################################
# Processors
########################################################################################################################
processors:
 # https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/processor/metricstransformprocessor
 metricstransform/1:
   transforms:
     - include: ^(.*)\.xyz$
       match_type: regexp
       action: update
       new_name: $${1}.zoom
     # Add a new label to all the metrics
     - include: .*
       match_type: regexp
       action: update
       operations:
         - action: add_label
           new_label: tf_agent
           new_value: otc-v1
 # https://github.com/open-telemetry/opentelemetry-collector/blob/main/processor/memorylimiterprocessor/README.md
 memory_limiter:
   check_interval: 10s
   limit_percentage: 50
   spike_limit_percentage: 30
 batch:
   # https://github.com/open-telemetry/opentelemetry-collector/blob/main/processor/batchprocessor/README.md
   # The batch processor accepts spans, metrics, or logs and places them into batches.
   # Batching helps better compress the data and reduce the number of outgoing connections required to transmit the data.
   # This processor supports both size and time based batching.
   send_batch_size: 1000
   send_batch_max_size: 1500
   timeout: 2s
 resourcedetection/system:
   detectors: ["system"]
   system:
    hostname_sources: ["os"]

########################################################################################################################
# Exporters
########################################################################################################################

exporters:
 # Multiple Exporters of the same "type" are possible, they have to be named <type>/<unique-name>
 file/file-A:
    path: /dev/stdout
 file/file-B:
    path: ./foo
    flush_interval: 5
    rotation:
      max_megabytes: 1
      max_days: 1
      max_backups: 2
      localtime: true
    format: proto
    compression: zstd

 logging:
   loglevel: debug
 # This enables a scraping endpoint for Prometheus on this OTel instance
 prometheus:
   endpoint: 0.0.0.0:8889
   namespace: "cdm"
   metric_expiration: 2m
 # https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/exporter/prometheusremotewriteexporter

 prometheusremotewrite/1:
   endpoint: "http://host.docker.internal:9090/api/v1/write"
   headers:
     Authorization: "Basic <masked>"
   tls:
    insecure: false

# prometheusremotewrite/2:
#   endpoint: "https://<masked>/api/v1/push"
#   tls:
#    insecure_skip_verify: true
#   headers:
#     Authorization: "Basic <masked>"
#     Content-Type: "application/x-protobuf"
#     Content-Encoding: "snappy"
#     X-Prometheus-Remote-Write-Version: "0.1.0"
#     X-Scope-OrgID: "fake"

extensions:
 health_check:
 pprof:
   endpoint: :1888
 zpages:
   endpoint: :55679

service:
 telemetry:
    metrics:
      level: detailed
      address: 0.0.0.0:8888
 extensions: [pprof, zpages, health_check]

 pipelines:
   # This pipeline is for incoming metrics (the metrics received from instrumented systems)
   metrics:
     receivers: [carbon, influxdb, otlp]
     # receivers: [influxdb, otlp, carbon]
     processors: [metricstransform/1, memory_limiter, batch]
     #exporters: [file/file-A, prometheus]
     # exporters: [prometheusremotewrite/2]
     exporters: [logging, prometheusremotewrite/1]

   # This pipeline is just for OTel observability (internal) metrics
   metrics/2:
     receivers: [prometheus_simple]
     processors: [resourcedetection/system, batch]
     #exporters: [file/file-A, prometheus]
     exporters: [logging, prometheus]
