receivers:
 # https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/receiver/simpleprometheusreceiver
 # This is being used to scrape the OTel Collector metrics from itself
 prometheus_simple:
   collection_interval: 10s
   endpoint: "0.0.0.0:8888"
 # Influx receiver (http) - Currently in Beta
 influxdb:
   # https://pkg.go.dev/github.com/open-telemetry/opentelemetry-collector-contrib/receiver/influxdbreceiver#section-readme
   # Apparently, only HTTP service endpoint for the line protocol receiver 
   endpoint: 0.0.0.0:19000

 # Carbon / Graphite receiver - Currently in Beta
 # All the details are present here:
 # https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/receiver/carbonreceiver
 carbon:
   endpoint: 0.0.0.0:2003
   transport: tcp
   tcp_idle_timeout: 10s
   parser:
     type: regex
     config:
       # Matches the first rule
       rules:
         # When the metrics are forwarded from Telegraf to OTel, the hostname is being added
         # <key_X> makes labels while <name_Y> makes metric names
         # Sender_Host.Cluster.c891.node74.Diamond-Telegraf.temperature.max
         - regexp: "^(?P<key_sender_host>[^.]+)\\.(?P<key_type>[^.]+)\\.(?P<key_custer_id>[^.]+)\\.(?P<key_node>[^.]+)\\.(?P<name_tkn3>[^.]+)\\.(?P<key_tkn4>[^.]+)\\.(?P<name_tkn5>[^.]+)$"
           name_prefix: ""
           type: gauge
         # Sender_Host.Cluster.c891.node74.Diamond-Telegraf.foo.bar.weather.xyz
         - regexp: "^(?P<key_sender_host>[^.]+)\\.(?P<key_type>[^.]+)\\.(?P<key_custer_id>[^.]+)\\.(?P<key_node>[^.]+)\\.(?P<key_tkn3>[^.]+)\\.(?P<key_tkn4>[^.]+)\\.(?P<key_tkn5>[^.]+)\\.(?P<name_measurement1>[^.]+)\\.(?P<name_measurement2>[^.]+)$"
           name_prefix: ""
           type: cumulative
       name_separator: "_"

 # OTLP receiver
 otlp:
   protocols:
     http:
       endpoint: 0.0.0.0:4318
     grpc:
       endpoint: 0.0.0.0:4317

processors:
 # https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/processor/metricstransformprocessor
 metricstransform:
   transforms:
     - include: ^(.*)\.xyz$
       match_type: regexp
       action: update
       new_name: $${1}.zoom
 # https://github.com/open-telemetry/opentelemetry-collector/blob/main/processor/memorylimiterprocessor/README.md
 memory_limiter:
   check_interval: 1s
   limit_percentage: 50
   spike_limit_percentage: 30
 batch:
   # https://github.com/open-telemetry/opentelemetry-collector/blob/main/processor/batchprocessor/README.md
   # The batch processor accepts spans, metrics, or logs and places them into batches.
   # Batching helps better compress the data and reduce the number of outgoing connections required to transmit the data.
   # This processor supports both size and time based batching.
   send_batch_size: 1000
   send_batch_max_size: 1500
   timeout: 2s
 resource:
   attributes:
     # Dummy processor - Just adds a key/value pair to each metric flowing through
     - key: test.key
       value: "test-value"
       action: insert
 resourcedetection/system:
   detectors: ["system"]
   system:
    hostname_sources: ["os"]


exporters:
 # Multiple Exporters of the same "type" are possible, they have to be named <type>/<unique-name>
 file/file-A:
    path: /dev/stdout
 file/file-B:
    path: ./foo
    flush_interval: 5
    rotation:
      max_megabytes: 1
      max_days: 1
      max_backups: 2
      localtime: true
    format: proto
    compression: zstd
 logging:
   loglevel: info
 # This enables a scraping endpoint for Prometheus
 prometheus:
   endpoint: 0.0.0.0:8889
   namespace: "cdm"
   metric_expiration: 2m
 # https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/exporter/prometheusremotewriteexporter
 prometheusremotewrite:
   endpoint: "http://host.docker.internal:9090/api/v1/write"
   tls:
    insecure: true

extensions:
 health_check:
 pprof:
   endpoint: :1888
 zpages:
   endpoint: :55679

service:
 telemetry:
    metrics:
      level: detailed
      address: 0.0.0.0:8888
 extensions: [pprof, zpages, health_check]
 pipelines:
   # This pipeline is for incoming metrics
   metrics:
     receivers: [influxdb, otlp, carbon]
     processors: [batch, memory_limiter]
     #exporters: [file/file-A, prometheus]
     exporters: [logging]
   # This pipeline is just for OTel metrics
#   metrics/2:
#     receivers: [prometheus_simple]
#     processors: [resourcedetection/system, batch]
#     #exporters: [file/file-A, prometheus]
#     exporters: [prometheusremotewrite]
